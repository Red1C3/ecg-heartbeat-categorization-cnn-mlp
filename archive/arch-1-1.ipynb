{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Started overfitting on almost epoch 20, until 15 it did well."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as layers\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#The dataset contains no header for columns, hence the header parameter\n",
    "dataframe=pd.read_csv('./mitbih_train.csv',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Last column is the category column, a scaler value from 0 to 4\n",
    "y=dataframe[dataframe.columns[-1:]]\n",
    "x=dataframe[dataframe.columns[:-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balances the dataset by oversampling it (it seems like it uses interpolation)\n",
    "# https://machinelearningmastery.com/smote-oversampling-for-imbalanced-classification/\n",
    "oversampler=SMOTE()\n",
    "x,y=oversampler.fit_resample(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72471\n",
      "72471\n",
      "72471\n",
      "72471\n",
      "72471\n"
     ]
    }
   ],
   "source": [
    "print(len(y[y[187] ==0 ]))\n",
    "print(len(y[y[187] ==1 ]))\n",
    "print(len(y[y[187] ==2 ]))\n",
    "print(len(y[y[187] ==3 ]))\n",
    "print(len(y[y[187] ==4 ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y=y.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x=x.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(362355, 187)"
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Change the value to only use a subset of the dataset (like for quick tests...)\n",
    "x=x[:362355][:][:]\n",
    "y=y[:362355][:]\n",
    "#Add data dimension, doesn't actually change the data but that's how the input is expected, like it could have multiple values per timestamp\n",
    "x=x.reshape([362355,187,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model=tf.keras.Sequential(\n",
    "    [layers.Conv1D(7, 7, activation='relu', input_shape=(187,1)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPool1D(),\n",
    "    layers.Conv1D(5,5,activation='relu'),\n",
    "     layers.BatchNormalization(),\n",
    "    layers.MaxPool1D(),\n",
    "     layers.Conv1D(3,3,activation='relu'),\n",
    "     layers.BatchNormalization(),\n",
    "     layers.MaxPool1D(),\n",
    "    layers.Flatten(),\n",
    "     layers.Dense(64,activation='relu'),\n",
    "     layers.Dense(32,activation='relu'),\n",
    "    layers.Dense(5,activation='softmax')] #softmax cuz categories\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 18s 44ms/step - loss: 0.8468 - accuracy: 0.6845\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 16s 44ms/step - loss: 0.2544 - accuracy: 0.9126\n",
      "Epoch 3/20\n",
      " 93/363 [======>.......................] - ETA: 11s - loss: 0.1844 - accuracy: 0.9374"
     ]
    }
   ],
   "source": [
    "model.compile('adam','sparse_categorical_crossentropy',metrics=['accuracy']) #this was with validation\n",
    "history=model.fit(x,y,batch_size=1000,epochs=20,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()  # Create a figure containing a single axes.\n",
    "ax.plot(history.epoch, history.history['accuracy'],label='accuracy');\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pd.read_csv('./mitbih_test.csv', header=None)\n",
    "y = dataframe[dataframe.columns[-1:]]\n",
    "x = dataframe[dataframe.columns[:-1]]\n",
    "y = y.to_numpy()\n",
    "\n",
    "x = x.to_numpy()\n",
    "\n",
    "x.shape\n",
    "x = x[:21892][:][:]\n",
    "y = y[:21892][:]\n",
    "x = x.reshape([21892, 187, 1])\n",
    "history.model.evaluate(x, y, batch_size=500, verbose=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "0b5916d98285d7f9256b24e73be44c1954c1d35b1fc6eb84af81e3fe0ccc5dea"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
